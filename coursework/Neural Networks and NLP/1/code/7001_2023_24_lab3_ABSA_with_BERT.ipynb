{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pr5PWYKGPi6R"
   },
   "source": [
    "In this lab we turn a pre-trained BERT model into a trainable Keras layer and apply it to the Aspect-Based Sentiment Analysis (ABSA). You can find the task description from (https://aclanthology.org/D19-1654.pdf).\n",
    "This task provides a review text dataset with aspects.\n",
    "Given a review and an aspect, we need to classify the sentiment conveyed towards this aspect on a three-point scale: POSITIVE, NEUTRAL or NEGATIVE.\n",
    "This is a multi-class classification task.\n",
    "\n",
    "BERT (Bidirectional Embedding Representations from Transformers) is a model for pre-training language representations that obtains state-of-the-art results on many NLP tasks. We demonstrate how to integrate BERT as a custom Keras layer using the Huggingface library.\n",
    "\n",
    "In this lab, you will learn:\n",
    "\n",
    "1) How to use the Huggingface library.\n",
    "\n",
    "2) How to integrate BERT in the models built previously.\n",
    "\n",
    "3) How to use the TPU from Colab. **Note**: Running BERT on the CPU will be very slow. Thus we recommend you to do this lab on a Colab TPU provided by Google."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pWgujXmGqzIC"
   },
   "source": [
    "# Lab 3 - Aspect-Based Sentiment Analysis with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4spJ5PRhGJ1l"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 13:48:08.023591: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-29 13:48:08.064623: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-29 13:48:08.064666: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-29 13:48:08.065816: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-29 13:48:08.072229: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-29 13:48:08.880322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Lambda, GlobalAveragePooling1D, Dense, Embedding\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import LSTM, RNN, Dropout, Input, LeakyReLU, Bidirectional,Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oimYsLssuSs"
   },
   "source": [
    "We first need to install the Huggingface's Transformers package. You can find the relevant doc from [here](https://huggingface.co/transformers/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AElpzsKFiZSo",
    "outputId": "de2905d1-7b20-48b5-c745-c01566afd4aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.0.dev0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebbamBD0xu5z"
   },
   "source": [
    "## Preprocessing and Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RbAMXQwqyVT8"
   },
   "source": [
    "In this lab we will use DistilBERT (https://arxiv.org/pdf/1910.01108.pdf) instead of BERT: DistilBERT is a smaller and faster Transformer model trained via distilling BERT. It has 40% less parameters than the bert-base-uncased model. It runs 60% faster, while preserving 97% of BERTâ€™s performance as measured on the GLUE language understanding benchmark.\n",
    "\n",
    "It is easy to switch between DistilBERT and BERT using the Huggingface transformers package. This package provides many pre-trained and pre-built models that are easy to use via a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V-cUTxt02dQb"
   },
   "source": [
    "Before using DistilBERT or BERT, we need a tokenizer. Generally speaking, every BERT related model has its own tokenizer, trained for this particular model.\n",
    "We can get the DistilBERT tokenizer from the **DistilBertTokenizer.from_pretrained** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272,
     "referenced_widgets": [
      "893bec7c1b3b42e680d7a7299187786a",
      "ead37c9899324f91b9b22b9bc8c9ccbd",
      "0469750a49fd44b8b9b628b4321511db",
      "860ece0c14cd47dd9df3acdcb541f4be",
      "554794d5270a4766bc57fdd95df3d7f8",
      "4343df99abf34f7f9f963b353ee61943",
      "a942a811b5ab424688f1d6e0c8cc1a30",
      "dfeaa05c47954e2cbb95108ee7eeb562",
      "cdd626bd92e34d1eb0416f09ba7b32c2",
      "fcb5766d74fb49368daec3256dfc46c2",
      "79646aec53e04a52b99cf52943c93670",
      "d22b269f152847b58f46d73a2a52d4b0",
      "7d835dce8e744be5882d7c0190edc945",
      "368c84bbd45d40c48a7c536003d3ff43",
      "d315d3fdc9af43be9c5fa8185007ebb5",
      "4e4c28615ae94075b914e2e6852de6d2",
      "12c99ebb8a4e48209a429a36839c526d",
      "238f57f7b87c483bac1a097c20abb2e1",
      "510ffa278f854c369bc5ec8f962cbe95",
      "05b9b3cb899245fea957be206b880d00",
      "63fc38298e264bc990155bad1d6de105",
      "b2951c3f7ce94f81987d673cf348ccc6",
      "30cdbbb98a6f48c29517dcb1251317bc",
      "5b34d2a6eaf6438496daa838f8d138c0",
      "dcdbad4fc7bc4023ad1084fddae62b4c",
      "944abd6e6bca444083e44d7f1c70f0ed",
      "ad51529da90b4c2d8b0a33d1f9011104",
      "13338950564542aeab9b155cba9fd394",
      "90b95127409e44298ea41695698e7254",
      "d8aebdca1e7146aaaee03e7de19f4ba1",
      "842b11a93a6149e3b25bc976d2efedab",
      "e42968b0c7a9497494824f87ccad20f4",
      "5e5d2279bb2648278581e7b0597b7041",
      "7e7deedeac164ffaa4178b65e685001a",
      "a150a9b9e5c4455fb3000c3944c97b54",
      "c9cc3ab579b247698de983b35af05754",
      "f71ab949f8d848739306d841e4cc407b",
      "39380579df544d5480346dd0e577a102",
      "c47eac0e8b6240fbae07a597abac1d5c",
      "a95fce6004f340d88b4119596742dc0d",
      "98f8f11b9ce34b1281a8732aaec23223",
      "e56014f836de41c997bbe17120e99bf8",
      "c22afea2bc37433d8938113de80c2550",
      "50774fc3abfa414482223d34a047f549"
     ]
    },
    "id": "hKj6Y_TydjeS",
    "outputId": "4e9e3597-eb94-4780-b896-8072bad5cfd6"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import DistilBertTokenizer, RobertaTokenizer\n",
    "import tqdm\n",
    "distil_bert = 'distilbert-base-uncased' # Pick a pre-trained model\n",
    "\n",
    "# Defining DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(distil_bert, do_lower_case=True, add_special_tokens=True,\n",
    "                                                max_length=128, pad_to_max_length=True)\n",
    "\n",
    "def tokenize(sentences, tokenizer, pad_length=128, pad_to_max_length=True ):\n",
    "    if type(sentences) == str:\n",
    "        inputs = tokenizer.encode_plus(sentences, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length,\n",
    "                                             return_attention_mask=True, return_token_type_ids=True)\n",
    "        return np.asarray(inputs['input_ids'], dtype='int32'), np.asarray(inputs['attention_mask'], dtype='int32'), np.asarray(inputs['token_type_ids'], dtype='int32')\n",
    "\n",
    "    input_ids, input_masks, input_segments = [],[],[]\n",
    "    for sentence in sentences:\n",
    "        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=pad_length, pad_to_max_length=pad_to_max_length,\n",
    "                                             return_attention_mask=True, return_token_type_ids=True)\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        input_masks.append(inputs['attention_mask'])\n",
    "        input_segments.append(inputs['token_type_ids'])\n",
    "\n",
    "    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32'), np.asarray(input_segments, dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRoKe2DKyi41",
    "outputId": "222b8990-9391-4413-dfd7-b5402cd4a034"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'capital', 'of', 'france', 'is', '[MASK]', '.'] \n",
      "\n",
      "['this', 'is', 'a', 'pre', '##train', '##ed', 'model', '.'] \n",
      "\n",
      "[ 101 1996 3007 1997 2605 2003  103 1012  102    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "[1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'] \n",
      "\n",
      "[ 101 1996 3007 1997 2605 2003  103 1012  102]\n",
      "[1 1 1 1 1 1 1 1 1]\n",
      "['[CLS]', 'the', 'capital', 'of', 'france', 'is', '[MASK]', '.', '[SEP]'] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2645: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.tokenize(\"The capital of France is [MASK].\")\n",
    "print(inputs,'\\n')\n",
    "\n",
    "inputs = tokenizer.tokenize(\"This is a pretrained model.\")\n",
    "print(inputs,'\\n')\n",
    "\n",
    "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer)\n",
    "print(ids)\n",
    "print(masks)\n",
    "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")\n",
    "\n",
    "ids,masks,segments = tokenize(\"The capital of France is [MASK].\", tokenizer, pad_to_max_length=False)\n",
    "print(ids)\n",
    "print(masks)\n",
    "print(tokenizer.convert_ids_to_tokens(ids),\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqMo6CPS3qJZ"
   },
   "source": [
    "Then we can use this tokenizer to tokenize our data. When working with word2vec and GloVe, you tokenized sentences into words yourself and then converted the tokens into GloVe indices. But in BERT, we must use the BERT tokenizer that uses sub-word tokens.\n",
    "\n",
    "For example, for the sentence: **This is a pretrained model.** our previous word-based tokenizer will generate the following tokens:\n",
    "\n",
    "**\"this\", \"is\", \"a\", \"pretrained\", \"model\", \".\"**\n",
    "\n",
    "Then you will find out that the token \"pretrained\" is not in the GloVe word dictionary. Thus we can not assign it a trained word vector.\n",
    "\n",
    "The BERT tokenizer will separate the word \"pretrained\" into three sub-word tokens:\n",
    "\n",
    "**'pre', '##train', '##ed'**\n",
    "\n",
    "BERT thus uses these three token vectors to represent the word \"pretrained\". You will also see that the BERT tokenizer adds the special [CLS] token and the sentence separator [SEP] token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J6OuZAA8sbdg"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqvPQvgvPv1W"
   },
   "source": [
    "### Downloading and preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EundMtGPpCdf"
   },
   "source": [
    "Unlike the IMDB dataset that is included and preprocessed by Keras, the dataset we will be using is the aspect-based sentiment analysis (ABSA)  dataset, which consists of 5,297 labeled reviews. These are split into 4,297 reviews for training and 500 reviews for testing and validation, respectively.\n",
    "\n",
    "For ABSA, sentiment polarities were assigned with respect to the aspect terms.  The start and end positions for each aspect term are provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NyuSzkafqNca",
    "outputId": "6f20d016-d108-46bb-ebb9-a672c75f74d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 11186\n",
      "Test entries: 1336\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "def downloadfile(url):\n",
    "  rq = requests.get(url)\n",
    "  open(url.split('/')[-1], 'wb').write(rq.content)\n",
    "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/train.xml')\n",
    "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/val.xml')\n",
    "downloadfile('https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data/MAMS-ATSA/raw/test.xml')\n",
    "\n",
    "\n",
    "# The code is modified from https://raw.githubusercontent.com/siat-nlp/MAMS-for-ABSA/master/data_process/utils.py\n",
    "from xml.etree.ElementTree import parse\n",
    "\n",
    "def parse_sentence_term(path, lowercase=False):\n",
    "    tree = parse(path)\n",
    "    sentences = tree.getroot()\n",
    "    data = []\n",
    "    split_char = '__split__'\n",
    "    for sentence in sentences:\n",
    "        text = sentence.find('text')\n",
    "        if text is None:\n",
    "            continue\n",
    "        text = text.text\n",
    "        if lowercase:\n",
    "            text = text.lower()\n",
    "        aspectTerms = sentence.find('aspectTerms')\n",
    "        if aspectTerms is None:\n",
    "            continue\n",
    "        for aspectTerm in aspectTerms:\n",
    "            term = aspectTerm.get('term')\n",
    "            if lowercase:\n",
    "                term = term.lower()\n",
    "            polarity = aspectTerm.get('polarity')\n",
    "            start = aspectTerm.get('from')\n",
    "            end = aspectTerm.get('to')\n",
    "            piece = [text , term,  polarity , start , end]\n",
    "            data.append(piece)\n",
    "    return data\n",
    "train = parse_sentence_term(\"train.xml\",True)\n",
    "dev = parse_sentence_term(\"val.xml\",True)\n",
    "test = parse_sentence_term(\"test.xml\",True)\n",
    "\n",
    "print(\"Training entries: {}\".format(len(train)))\n",
    "print(\"Test entries: {}\".format(len(test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U4iCV9-rmay"
   },
   "source": [
    "Letâ€™s first see some examples from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-gjWRAuqg5s",
    "outputId": "1d3685a2-02f4-42de-e3e8-99ca2cbc3766"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SENTENCE \t ASPECT \t LABEL \t ASPECT-START-INDEX \t ASPECT-END-INDEX\n",
      "['the decor is not special at all but their food and amazing prices make up for it.', 'decor', 'negative', '4', '9']\n",
      "['the decor is not special at all but their food and amazing prices make up for it.', 'food', 'positive', '42', '46']\n",
      "['the decor is not special at all but their food and amazing prices make up for it.', 'prices', 'positive', '59', '65']\n",
      "['when tables opened up, the manager sat another party before us.', 'tables', 'neutral', '5', '11']\n",
      "['when tables opened up, the manager sat another party before us.', 'manager', 'negative', '27', '34']\n"
     ]
    }
   ],
   "source": [
    "print(\"SENTENCE \\t ASPECT \\t LABEL \\t ASPECT-START-INDEX \\t ASPECT-END-INDEX\")\n",
    "print(train[0])\n",
    "print(train[1])\n",
    "print(train[2])\n",
    "print(train[3])\n",
    "print(train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gMCH1OoDrSNR",
    "outputId": "e1032fcc-e1d5-45e8-817e-a537830b19d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_dev_aspect_int[0]:\n",
      "[ 101 8974  102    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0]\n",
      "x_dev_aspect_masks[0]:\n",
      "[1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "x_dev_review_int[0]:\n",
      "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
      "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
      " 26852  1011  1011  2175  2091  2307  1012   102     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "x_dev_review_masks[0]:\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Please write your code to generate the following data\n",
    "# x_train_review_int\n",
    "# x_train_review_masks\n",
    "# x_train_aspect_int\n",
    "# x_train_aspect_masks\n",
    "\n",
    "# x_dev_review_int\n",
    "# x_dev_review_masks\n",
    "# x_dev_aspect_int\n",
    "# x_dev_aspect_masks\n",
    "\n",
    "# x_test_review_int\n",
    "# x_test_review_masks\n",
    "# x_test_aspect_int\n",
    "# x_test_aspect_masks\n",
    "\n",
    "# your code goes here\n",
    "train_reviews=[item[0] for item in train]\n",
    "train_aspects=[item[1] for item in train]\n",
    "dev_reviews=[item[0] for item in dev]\n",
    "dev_aspects=[item[1] for item in dev]\n",
    "test_reviews=[item[0] for item in test]\n",
    "test_aspects=[item[1] for item in test]\n",
    "\n",
    "# Tokenization for Training Dataset\n",
    "x_train_review_int, x_train_review_masks, _ = tokenize(train_reviews, tokenizer)\n",
    "x_train_aspect_int, x_train_aspect_masks, _ = tokenize(train_aspects, tokenizer)\n",
    "\n",
    "# Tokenization for Development (Validation) Dataset\n",
    "x_dev_review_int, x_dev_review_masks, _ = tokenize(dev_reviews, tokenizer)\n",
    "x_dev_aspect_int, x_dev_aspect_masks, _ = tokenize(dev_aspects, tokenizer)\n",
    "\n",
    "# Tokenization for Testing Dataset\n",
    "x_test_review_int, x_test_review_masks, _ = tokenize(test_reviews, tokenizer)\n",
    "x_test_aspect_int, x_test_aspect_masks, _ = tokenize(test_aspects, tokenizer)\n",
    "\n",
    "\n",
    "# You can check the results as follows:\n",
    "assert len(x_train_aspect_int) == len(train)\n",
    "assert len(x_train_aspect_masks) == len(x_train_aspect_int)\n",
    "assert len(x_test_aspect_int) == len(test)\n",
    "assert len(x_test_aspect_masks) == len(x_test_aspect_int)\n",
    "print(\"x_dev_aspect_int[0]:\")\n",
    "print(x_dev_aspect_int[0])\n",
    "print(\"x_dev_aspect_masks[0]:\")\n",
    "print(x_dev_aspect_masks[0])\n",
    "print(\"x_dev_review_int[0]:\")\n",
    "print(x_dev_review_int[0])\n",
    "print(\"x_dev_review_masks[0]:\")\n",
    "print(x_dev_review_masks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tvuu4KhStqei"
   },
   "source": [
    "Using the BERT `tokenize` function above, we can turn text and aspect words to integers:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IreFXgruZot"
   },
   "source": [
    "We one-hot encode the labels, using 4 (Binary:100) to represent \"positive\", 2 (Binary:010) for \"neutral\", and 1 (Binary:001) for \"negative\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abIb7Fe5u3GQ",
    "outputId": "c2d474ed-974b-4383-c929-de53e1728a16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "[1 0 0]\n",
      "[1 0 0]\n",
      "[0 1 0]\n",
      "[0 0 1]\n"
     ]
    }
   ],
   "source": [
    "def label2int(dataset):\n",
    "  y = []\n",
    "  for example in dataset:\n",
    "    if example[2].lower() == \"negative\":\n",
    "      y.append([0,0,1])\n",
    "    elif example[2].lower() == \"neutral\":\n",
    "      y.append([0,1,0])\n",
    "    else:\n",
    "      # assert example[2].lower() == \"positive\"\n",
    "      y.append([1,0,0])\n",
    "  return y\n",
    "\n",
    "y_train = label2int(train)\n",
    "y_dev = label2int(dev)\n",
    "y_test = label2int(test)\n",
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train[1])\n",
    "print(y_train[2])\n",
    "print(y_train[3])\n",
    "print(y_train[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9TnnSuspvC5b"
   },
   "source": [
    "Now we have almost finished the data preprocessing. Unlike in the previous labs, there are two model inputs: review and aspect. The easiest way is to combine the review and aspect into one sentence and then input it into the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKOiVVXQu-_I",
    "outputId": "30ea917f-8612-437b-a863-4fb1824332e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
      "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
      " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] \n",
      "\n",
      "[  101  2044  1037  3232  1997  8974  1010  1996 18726  1011  1011  1045\n",
      "  2066  1996 27940  1013 24792  2621  4897  1998  1996 13675 11514  6508\n",
      " 26852  1011  1011  2175  2091  2307  1012   102  8974   102     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Please write your code to combine sentences and aspect words into the following varibles\n",
    "\n",
    "# x_train_int\n",
    "# x_train_masks\n",
    "# x_dev_int\n",
    "# x_dev_masks\n",
    "# x_test_int\n",
    "# x_test_masks\n",
    "\n",
    "# Tips:\n",
    "# 1) Use the special token [SEP] to concatenate sentences and aspect words\n",
    "# 2) Make sure they are paded/truncated to a max length\n",
    "\n",
    "# your code goes here\n",
    "def combineSentAndAspect(sentences, aspect_words, tokenizer, max_length=128):\n",
    "    combined_texts = [sentence + \" [SEP] \" + aspect for sentence, aspect in zip(sentences, aspect_words)]\n",
    "    input_ids, attention_masks = [], []\n",
    "\n",
    "    for text in combined_texts:\n",
    "        inputs = tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True\n",
    "        )\n",
    "        input_ids.append(inputs['input_ids'])\n",
    "        attention_masks.append(inputs['attention_mask'])\n",
    "\n",
    "    return np.array(input_ids), np.array(attention_masks)\n",
    "\n",
    "\n",
    "x_train_int, x_train_masks = combineSentAndAspect(train_reviews, train_aspects, tokenizer)\n",
    "x_dev_int, x_dev_masks = combineSentAndAspect(dev_reviews, dev_aspects, tokenizer)\n",
    "x_test_int, x_test_masks = combineSentAndAspect(test_reviews, test_aspects, tokenizer)\n",
    "\n",
    "# Don't forget the to use the np.array function to wrap the outputs\n",
    "x_train_int_np = np.array(x_train_int)\n",
    "x_train_masks_np = np.array(x_train_masks)\n",
    "x_dev_int_np = np.array(x_dev_int)\n",
    "x_dev_masks_np = np.array(x_dev_masks)\n",
    "x_test_int_np = np.array(x_test_int)\n",
    "x_test_masks_np = np.array(x_test_masks)\n",
    "\n",
    "\n",
    "print(x_dev_int[0])\n",
    "print(x_dev_masks[0],'\\n')\n",
    "print(x_dev_int_np[0])\n",
    "print(x_dev_masks_np[0]) # sentence + aspect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqvUGIwwGJqu"
   },
   "source": [
    "## Model 1: Prebuilt Sequence Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hSxC41ln07im"
   },
   "source": [
    "The Huggingface transformer package provides many prebuilt models. Now let us try a sequence classification model based on DistilBERT.\n",
    "\n",
    "The models with BERT are much bigger than our previous models. To run it faster, we can use TPU. Detailed guidelines on how to use TPU can be found from https://www.tensorflow.org/guide/tpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158,
     "referenced_widgets": [
      "e93c54504c2945f5893317667b214345",
      "47ad13b14a2948fd9e6c682d435430df",
      "a5ee247f216b46e79b33395015869823",
      "83d4629b79894fb78986ed8b1e57742d",
      "5a376e9771bd4be7958eee76e4b2c1f7",
      "07a09ec8b7044678a162e6f0c4e3c951",
      "c9c7a644615247298cd663190f318c84",
      "ee7f36305300439789d81a05e548da47",
      "d98f2a3af21c4cdc973be9dcecc96505",
      "2f7c5973a041492c8ea91690792f02f7",
      "5fca6d29fce1400c803b108b013bf6ff"
     ]
    },
    "id": "1gXFbb2cxBlw",
    "outputId": "67ae12ae-eb01-4fef-efb1-3bd9e315e4c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-29 13:48:30.877527: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFDistilBertForSequenceClassification, DistilBertConfig\n",
    "import tensorflow as tf\n",
    "\n",
    "distil_bert = 'distilbert-base-uncased'\n",
    "\n",
    "config = DistilBertConfig(num_labels=3)\n",
    "config.output_hidden_states = False\n",
    "\n",
    "def create_TFDistilBertForSequenceClassification():\n",
    "  transformer_model = TFDistilBertForSequenceClassification.from_pretrained(distil_bert, config = config)\n",
    "  input_ids = tf.keras.layers.Input(shape=(128,), name='input_token', dtype='int32')\n",
    "  input_masks_ids = tf.keras.layers.Input(shape=(128,), name='masked_token', dtype='int32')\n",
    "  X = transformer_model(input_ids, input_masks_ids)\n",
    "  return tf.keras.Model(inputs=[input_ids, input_masks_ids], outputs = X)\n",
    "\n",
    "\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "  # Create distribution strategy\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "  # Create model on TPU:\n",
    "  with strategy.scope():\n",
    "    model = create_TFDistilBertForSequenceClassification()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "  model = create_TFDistilBertForSequenceClassification()\n",
    "  model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CPFj0CMx9mw",
    "outputId": "e12fae7d-bfb9-4df8-bd1d-fbbd26f684f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_token (InputLayer)    [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " masked_token (InputLayer)   [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_for_sequenc  TFSequenceClassifierOutput   6695577   ['input_token[0][0]',         \n",
      " e_classification (TFDistil  (loss=None, logits=(None,    9          'masked_token[0][0]']        \n",
      " BertForSequenceClassificat  3),                                                                  \n",
      " ion)                         hidden_states=None, atten                                           \n",
      "                             tions=None)                                                          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66955779 (255.42 MB)\n",
      "Trainable params: 66955779 (255.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "zQQH5lE_33Vn",
    "outputId": "7fb4ce37-7c6e-4ff2-d939-3e8e5d2cb8f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 174s 174s/step - loss: 3.3769 - accuracy: 0.3600 - val_loss: 4.0689 - val_accuracy: 0.4535\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 148s 148s/step - loss: 3.6546 - accuracy: 0.4800 - val_loss: 5.0714 - val_accuracy: 0.3026\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 151s 151s/step - loss: 4.4728 - accuracy: 0.3200 - val_loss: 6.7807 - val_accuracy: 0.3026\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_int_np[:50],x_train_masks_np[:50]],\n",
    "                    y_train[:50],\n",
    "                    epochs=3,\n",
    "                    batch_size=512,\n",
    "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "lQcytuBdaWVp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 168s 4s/step - loss: 6.7893 - accuracy: 0.2994\n",
      "[6.789268493652344, 0.299401193857193]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdZ4nl08vp9A"
   },
   "source": [
    "\n",
    "## Model 2: Neural bag of words using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-rz3BnMmgA1"
   },
   "source": [
    "Now we want to build the neural network model. We  are going to have a hidden layer with 16 hidden units.\n",
    "\n",
    "First, we want to transform each index to a BERT embedded vector and then average all vectors to a single one. It has been showed that unweighted average of word vectors outperforms many complicated networks that model semantic and syntactic compositionality. As an example you can take a look at this: (http://anthology.aclweb.org/P/P15/P15-1162.pdf)\n",
    "\n",
    "To average we need to ignore padded zeros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DStlnRQRf-4v"
   },
   "outputs": [],
   "source": [
    "class GlobalAveragePooling1DMasked(GlobalAveragePooling1D):\n",
    "    def call(self, x, mask=None):\n",
    "        if mask != None:\n",
    "            return K.sum(x, axis=1) / K.sum(mask, axis=1)\n",
    "        else:\n",
    "            return super().call(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "8fTwmYDvNEyT"
   },
   "outputs": [],
   "source": [
    "from transformers import TFDistilBertModel, DistilBertConfig\n",
    "\n",
    "def get_BERT_layer():\n",
    "  distil_bert = 'distilbert-base-uncased'\n",
    "  config = DistilBertConfig(dropout=0.2, attention_dropout=0.2)\n",
    "  config.output_hidden_states = False\n",
    "  return TFDistilBertModel.from_pretrained(distil_bert, config = config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VICS9rY8C7KH",
    "outputId": "606891be-9a67-4bf4-eaff-a39f776c6a0e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hdepth=16\n",
    "MAX_SEQUENCE_LENGTH = 128\n",
    "EMBED_SIZE=100\n",
    "\n",
    "\n",
    "def create_bag_of_words_BERT():\n",
    "  # your code goes here\n",
    "  input_ids_in = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')\n",
    "  input_masks_in = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "\n",
    "  bert_embeddings = get_BERT_layer()\n",
    "  embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "\n",
    "  pooled_sent= GlobalAveragePooling1DMasked()(embedded_sent)\n",
    "  # Hint: you can use the following parameters: activation='sigmoid',kernel_initializer='glorot_uniform'\n",
    "  hidden_output= Dense(hdepth, activation='sigmoid', kernel_initializer='glorot_uniform')(pooled_sent)\n",
    "  # Hint: you can use the following parameters: activation='softmax',kernel_initializer='glorot_uniform'\n",
    "  label= Dense(3, activation='softmax', kernel_initializer='glorot_uniform')(hidden_output)\n",
    "\n",
    "  return Model(inputs=[input_ids_in,input_masks_in], outputs=[label],name='Model2_BERT')\n",
    "\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "  # Create distribution strategy\n",
    "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "  tf.config.experimental_connect_to_cluster(tpu)\n",
    "  tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "  strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "  # Create model\n",
    "  with strategy.scope():\n",
    "    model2 = create_bag_of_words_BERT()\n",
    "    optimizer2 = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "    model2.compile(optimizer=optimizer2, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "else:\n",
    "  model2 = create_bag_of_words_BERT()\n",
    "  model2.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GebkoriE5daJ",
    "outputId": "dab1f34a-57cd-43ee-c469-b2b097c1451d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model2_BERT\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)    [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model (TFDi  TFBaseModelOutput(last_hid   6636288   ['input_ids[0][0]',           \n",
      " stilBertModel)              den_state=(None, 128, 768)   0          'input_masks[0][0]']         \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " global_average_pooling1d_m  (None, 768)                  0         ['tf_distil_bert_model[0][0]']\n",
      " asked (GlobalAveragePoolin                                                                       \n",
      " g1DMasked)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 16)                   12304     ['global_average_pooling1d_mas\n",
      "                                                                    ked[0][0]']                   \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 3)                    51        ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66375235 (253.20 MB)\n",
      "Trainable params: 66375235 (253.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "S0SbsCsxF1zi",
    "outputId": "b956a812-34ea-4489-85a8-176f7e7bedbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 163s 163s/step - loss: 0.9343 - accuracy: 0.2000 - val_loss: 0.6368 - val_accuracy: 0.4535\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 157s 157s/step - loss: 0.6360 - accuracy: 0.4800 - val_loss: 0.6460 - val_accuracy: 0.4535\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 155s 155s/step - loss: 0.6332 - accuracy: 0.4800 - val_loss: 0.6331 - val_accuracy: 0.4535\n"
     ]
    }
   ],
   "source": [
    "history = model2.fit([x_train_int_np[:50],x_train_masks_np[:50]],\n",
    "                    y_train[:50],\n",
    "                    epochs=3,\n",
    "                    batch_size=512,\n",
    "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "rs0_vvG6UQtv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 168s 4s/step - loss: 0.6328 - accuracy: 0.4543\n",
      "[0.6327853798866272, 0.454341322183609]\n"
     ]
    }
   ],
   "source": [
    "results = model2.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "awOphcCnhEwv"
   },
   "source": [
    "## Model 3: CNN or LSTM with BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E5codSzohQ_9"
   },
   "source": [
    "Please follow the architecture for model2 to construct a CNN or an LSTM model on the top of BERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "JMiiWhW4hPRA"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# your code goes here\n",
    "\n",
    "def create_lstm_on_bert():\n",
    "    input_ids_in = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_ids')\n",
    "    input_masks_in = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype=tf.int32, name='input_masks')\n",
    "\n",
    "    bert_embeddings = get_BERT_layer()\n",
    "    embedded_sent = bert_embeddings(input_ids_in, attention_mask=input_masks_in)[0]\n",
    "\n",
    "    lstm_layer = LSTM(units=100)(embedded_sent)\n",
    "\n",
    "    label = Dense(3, activation='softmax', kernel_initializer='glorot_uniform')(lstm_layer)\n",
    "\n",
    "    return Model(inputs=[input_ids_in, input_masks_in], outputs=label, name='Model3_LSTM')\n",
    "\n",
    "\n",
    "use_tpu = True\n",
    "if use_tpu:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    with strategy.scope():\n",
    "      model3 = create_lstm_on_bert()\n",
    "      optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "      model3.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "else:\n",
    "    model3 = create_lstm_on_bert()\n",
    "    model3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "zcp7R1035ozX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Model3_LSTM\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)      [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " input_masks (InputLayer)    [(None, 128)]                0         []                            \n",
      "                                                                                                  \n",
      " tf_distil_bert_model_1 (TF  TFBaseModelOutput(last_hid   6636288   ['input_ids[0][0]',           \n",
      " DistilBertModel)            den_state=(None, 128, 768)   0          'input_masks[0][0]']         \n",
      "                             , hidden_states=None, atte                                           \n",
      "                             ntions=None)                                                         \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 100)                  347600    ['tf_distil_bert_model_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 3)                    303       ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 66710783 (254.48 MB)\n",
      "Trainable params: 66710783 (254.48 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "c9HmJNzNpIEM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "1/1 [==============================] - 173s 173s/step - loss: 0.7397 - accuracy: 0.2200 - val_loss: 0.7445 - val_accuracy: 0.4535\n",
      "Epoch 2/3\n",
      "1/1 [==============================] - 160s 160s/step - loss: 0.7050 - accuracy: 0.4800 - val_loss: 0.6835 - val_accuracy: 0.4535\n",
      "Epoch 3/3\n",
      "1/1 [==============================] - 166s 166s/step - loss: 0.6525 - accuracy: 0.4800 - val_loss: 0.7240 - val_accuracy: 0.3026\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit([x_train_int_np[:50],x_train_masks_np[:50]],\n",
    "                    y_train[:50],\n",
    "                    epochs=3,\n",
    "                    batch_size=512,\n",
    "                    validation_data=([x_dev_int_np,x_dev_masks_np], y_dev),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W7TXLjQhpY--"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/42 [============================>.] - ETA: 4s - loss: 0.7219 - accuracy: 0.3011"
     ]
    }
   ],
   "source": [
    "results = model3.evaluate([x_test_int_np,x_test_masks_np], y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0469750a49fd44b8b9b628b4321511db": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dfeaa05c47954e2cbb95108ee7eeb562",
      "max": 28,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cdd626bd92e34d1eb0416f09ba7b32c2",
      "value": 28
     }
    },
    "05b9b3cb899245fea957be206b880d00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "07a09ec8b7044678a162e6f0c4e3c951": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c99ebb8a4e48209a429a36839c526d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "13338950564542aeab9b155cba9fd394": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "238f57f7b87c483bac1a097c20abb2e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2f7c5973a041492c8ea91690792f02f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30cdbbb98a6f48c29517dcb1251317bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5b34d2a6eaf6438496daa838f8d138c0",
       "IPY_MODEL_dcdbad4fc7bc4023ad1084fddae62b4c",
       "IPY_MODEL_944abd6e6bca444083e44d7f1c70f0ed"
      ],
      "layout": "IPY_MODEL_ad51529da90b4c2d8b0a33d1f9011104"
     }
    },
    "368c84bbd45d40c48a7c536003d3ff43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_510ffa278f854c369bc5ec8f962cbe95",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_05b9b3cb899245fea957be206b880d00",
      "value": 231508
     }
    },
    "39380579df544d5480346dd0e577a102": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4343df99abf34f7f9f963b353ee61943": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "47ad13b14a2948fd9e6c682d435430df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_07a09ec8b7044678a162e6f0c4e3c951",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c9c7a644615247298cd663190f318c84",
      "value": "model.safetensors:â€‡100%"
     }
    },
    "4e4c28615ae94075b914e2e6852de6d2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50774fc3abfa414482223d34a047f549": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "510ffa278f854c369bc5ec8f962cbe95": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "554794d5270a4766bc57fdd95df3d7f8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a376e9771bd4be7958eee76e4b2c1f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b34d2a6eaf6438496daa838f8d138c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13338950564542aeab9b155cba9fd394",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_90b95127409e44298ea41695698e7254",
      "value": "tokenizer.json:â€‡100%"
     }
    },
    "5e5d2279bb2648278581e7b0597b7041": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fca6d29fce1400c803b108b013bf6ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63fc38298e264bc990155bad1d6de105": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79646aec53e04a52b99cf52943c93670": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d835dce8e744be5882d7c0190edc945": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12c99ebb8a4e48209a429a36839c526d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_238f57f7b87c483bac1a097c20abb2e1",
      "value": "vocab.txt:â€‡100%"
     }
    },
    "7e7deedeac164ffaa4178b65e685001a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a150a9b9e5c4455fb3000c3944c97b54",
       "IPY_MODEL_c9cc3ab579b247698de983b35af05754",
       "IPY_MODEL_f71ab949f8d848739306d841e4cc407b"
      ],
      "layout": "IPY_MODEL_39380579df544d5480346dd0e577a102"
     }
    },
    "83d4629b79894fb78986ed8b1e57742d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f7c5973a041492c8ea91690792f02f7",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5fca6d29fce1400c803b108b013bf6ff",
      "value": "â€‡268M/268Mâ€‡[00:03&lt;00:00,â€‡81.6MB/s]"
     }
    },
    "842b11a93a6149e3b25bc976d2efedab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "860ece0c14cd47dd9df3acdcb541f4be": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcb5766d74fb49368daec3256dfc46c2",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_79646aec53e04a52b99cf52943c93670",
      "value": "â€‡28.0/28.0â€‡[00:00&lt;00:00,â€‡609B/s]"
     }
    },
    "893bec7c1b3b42e680d7a7299187786a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ead37c9899324f91b9b22b9bc8c9ccbd",
       "IPY_MODEL_0469750a49fd44b8b9b628b4321511db",
       "IPY_MODEL_860ece0c14cd47dd9df3acdcb541f4be"
      ],
      "layout": "IPY_MODEL_554794d5270a4766bc57fdd95df3d7f8"
     }
    },
    "90b95127409e44298ea41695698e7254": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "944abd6e6bca444083e44d7f1c70f0ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e42968b0c7a9497494824f87ccad20f4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_5e5d2279bb2648278581e7b0597b7041",
      "value": "â€‡466k/466kâ€‡[00:00&lt;00:00,â€‡6.59MB/s]"
     }
    },
    "98f8f11b9ce34b1281a8732aaec23223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a150a9b9e5c4455fb3000c3944c97b54": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c47eac0e8b6240fbae07a597abac1d5c",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a95fce6004f340d88b4119596742dc0d",
      "value": "config.json:â€‡100%"
     }
    },
    "a5ee247f216b46e79b33395015869823": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee7f36305300439789d81a05e548da47",
      "max": 267954768,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d98f2a3af21c4cdc973be9dcecc96505",
      "value": 267954768
     }
    },
    "a942a811b5ab424688f1d6e0c8cc1a30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a95fce6004f340d88b4119596742dc0d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad51529da90b4c2d8b0a33d1f9011104": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2951c3f7ce94f81987d673cf348ccc6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c22afea2bc37433d8938113de80c2550": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c47eac0e8b6240fbae07a597abac1d5c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9c7a644615247298cd663190f318c84": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9cc3ab579b247698de983b35af05754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_98f8f11b9ce34b1281a8732aaec23223",
      "max": 483,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e56014f836de41c997bbe17120e99bf8",
      "value": 483
     }
    },
    "cdd626bd92e34d1eb0416f09ba7b32c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d22b269f152847b58f46d73a2a52d4b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7d835dce8e744be5882d7c0190edc945",
       "IPY_MODEL_368c84bbd45d40c48a7c536003d3ff43",
       "IPY_MODEL_d315d3fdc9af43be9c5fa8185007ebb5"
      ],
      "layout": "IPY_MODEL_4e4c28615ae94075b914e2e6852de6d2"
     }
    },
    "d315d3fdc9af43be9c5fa8185007ebb5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_63fc38298e264bc990155bad1d6de105",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_b2951c3f7ce94f81987d673cf348ccc6",
      "value": "â€‡232k/232kâ€‡[00:00&lt;00:00,â€‡2.17MB/s]"
     }
    },
    "d8aebdca1e7146aaaee03e7de19f4ba1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d98f2a3af21c4cdc973be9dcecc96505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dcdbad4fc7bc4023ad1084fddae62b4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d8aebdca1e7146aaaee03e7de19f4ba1",
      "max": 466062,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_842b11a93a6149e3b25bc976d2efedab",
      "value": 466062
     }
    },
    "dfeaa05c47954e2cbb95108ee7eeb562": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e42968b0c7a9497494824f87ccad20f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e56014f836de41c997bbe17120e99bf8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e93c54504c2945f5893317667b214345": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_47ad13b14a2948fd9e6c682d435430df",
       "IPY_MODEL_a5ee247f216b46e79b33395015869823",
       "IPY_MODEL_83d4629b79894fb78986ed8b1e57742d"
      ],
      "layout": "IPY_MODEL_5a376e9771bd4be7958eee76e4b2c1f7"
     }
    },
    "ead37c9899324f91b9b22b9bc8c9ccbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4343df99abf34f7f9f963b353ee61943",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a942a811b5ab424688f1d6e0c8cc1a30",
      "value": "tokenizer_config.json:â€‡100%"
     }
    },
    "ee7f36305300439789d81a05e548da47": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f71ab949f8d848739306d841e4cc407b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c22afea2bc37433d8938113de80c2550",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_50774fc3abfa414482223d34a047f549",
      "value": "â€‡483/483â€‡[00:00&lt;00:00,â€‡7.45kB/s]"
     }
    },
    "fcb5766d74fb49368daec3256dfc46c2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
