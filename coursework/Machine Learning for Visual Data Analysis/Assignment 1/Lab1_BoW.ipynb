{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMXK-BMUlVD-"
      },
      "source": [
        "## 0. Introduction\n",
        "\n",
        "The aim of this lab is to get familiar with **Image Classification** using  **KNN**, and **SVM** models.\n",
        "\n",
        "\n",
        "1.   This lab is the first course-work activity **Assignment 1**\n",
        "2.   A report answering the <font color = 'red'>**questions in</font><font color = \"maroon\"> red**</font> should be submitted on QMplus along with the completed Notebook.\n",
        "3. The report should be a separate file in **pdf format** (so **NOT** *doc, docx, notebook* etc.), well identified with your name, student number, assignment number (for instance, Assignment 1), module code.\n",
        "4. Make sure that **any figures or code** you comment on, are **included in the report**.\n",
        "5. No other means of submission other than the appropriate QM+ link is acceptable at any time (so NO email attachments, etc.)\n",
        "6. **PLAGIARISM** <ins>is an irreversible non-negotiable failure in the course</ins> (if in doubt of what constitutes plagiarism, ask!).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J07-lDzQlMhC"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJEs1U4DDRD3"
      },
      "source": [
        "Upload the `images.zip` file to colab and unzip using the cells below. Remember that the file upload is ephemeral, so the files are uploaded only for eac session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwr0gj29mUhF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvqyd2tUQ-5Y"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/analysis\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIDI5q-_Drsk"
      },
      "outputs": [],
      "source": [
        "!unzip images.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w1MqIBQnOkS"
      },
      "source": [
        "The **image** folder contains 5 sub-directories each of which contains images from one of the following image classes: airplanes, cars, dog, faces and keyboard. In each class there are 80 images, the first 60 will be used for training and the rest will be used for testing.\n",
        "\n",
        "An example of the images can be seen below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz9DTaPsncKW"
      },
      "outputs": [],
      "source": [
        "## example of 5 images from each class\n",
        "example_img = list()\n",
        "for root, dirs, _ in os.walk('image/'):\n",
        "    for class_folder in dirs:\n",
        "      img_files = os.listdir(os.path.join(root, class_folder))\n",
        "      img_files = [\n",
        "          os.path.join(*[root, class_folder, filename]) for filename in img_files\n",
        "          ]\n",
        "      example_img.extend(img_files[:5])\n",
        "\n",
        "img_lst = list()\n",
        "for imgf in example_img:\n",
        "    img = cv2.imread(imgf)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img_lst.append(img)\n",
        "\n",
        "f, axarr = plt.subplots(5,5,figsize=(15, 15))\n",
        "axarr = axarr.flatten()\n",
        "for img, ax in zip(img_lst, axarr):\n",
        "    ax.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqOA4UmnSGrD"
      },
      "source": [
        "SIFT (Scale Invariant Fourier Transform) Detector is used in the detection of interest points on an input image. It allows identification of localized features in images. The following script generates images with keypoints for the above examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "peV_wb5QTEcd"
      },
      "outputs": [],
      "source": [
        "f, axarr = plt.subplots(5,5,figsize=(15, 15))\n",
        "axarr = axarr.flatten()\n",
        "for img, ax in zip(img_lst, axarr):\n",
        "    # Converting image to grayscale\n",
        "    gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
        "    # Applying SIFT detector\n",
        "    sift = cv2.xfeatures2d.SIFT_create()\n",
        "    kp = sift.detect(gray, None)\n",
        "    # Marking the keypoint on the image using circles\n",
        "    img=cv2.drawKeypoints(gray,kp,img,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
        "    ax.imshow(img)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaLYWLTVniU7"
      },
      "source": [
        "The first step is to compute the SIFT descriptors for all images in the data directory. We have precomputed the SIFT image descriptors for 900 predifined patches in each image. These can be imported from `all_features.mat` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TVNv41pVigD"
      },
      "outputs": [],
      "source": [
        "label = {'airplanes':0, 'cars':1, 'dog':2, 'faces':3, 'keyboard':4}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGxOYskddOPO"
      },
      "outputs": [],
      "source": [
        "import scipy.io\n",
        "\n",
        "mat = scipy.io.loadmat('all_features.mat')\n",
        "train_des = mat['TrainMat']\n",
        "test_des = mat['TestMat']\n",
        "train_label = list()\n",
        "test_label = list()\n",
        "for i in range(5):\n",
        "    train_label.extend([i] * 60)\n",
        "    test_label.extend([i] * 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeUZiqRqWHf7"
      },
      "outputs": [],
      "source": [
        "train_des = train_des.reshape((300, -1, 128)) # 300个图像\n",
        "test_des = test_des.reshape((100, -1, 128))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y3Rnvlxn79D"
      },
      "source": [
        "## 2. Dictionary Creation - Feature Quantization\n",
        "\n",
        "Task 1: Using [sklearn KMeans](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html), create a dictionary by clustering a **subset** (eg. 6000) of the extracted descriptors.\n",
        "\n",
        "Use a dictionary of 500 words and the `elkan` algorithm to compute the dictionary.\n",
        "\n",
        "<font color = 'red'>Explain the input and the output of the K-means; what are the input and output dimensions? what is the use of the dictionary?</font> [3 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odE43mONooNG"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "# Step 1: create an array (N x 128) of all descriptors in the training set (not by image)\n",
        "all_descriptors = np.vstack(train_des) # 垂直堆叠在一起后，将所有图像的描述符堆叠成一个大的二维数组\n",
        "subset_descriptors = all_descriptors[:6000, :]\n",
        "\n",
        "# Step 2: use Kmeans to create the Dictionary (the resulting Dictionary should have K words and 128 features)\n",
        "K = 500\n",
        "kmeans = KMeans(n_clusters=K, algorithm='elkan', random_state=42)\n",
        "kmeans.fit(subset_descriptors)\n",
        "dictionary = kmeans.cluster_centers_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stJoQfvBpLjJ"
      },
      "source": [
        "Task 2: Assign each image descriptor in the training and test sets, to the nearest codeword cluster. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfXhKrMApl9f"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "train_assignments = kmeans.predict(train_des.reshape(-1, 128))\n",
        "test_assignments = kmeans.predict(test_des.reshape(-1, 128)) #输出一个与输入特征描述符数量相同的数组，数组中的每个元素是对应描述符被分配到的聚类中心的索引\n",
        "\n",
        "train_reAssignments = train_assignments.reshape(train_des.shape[:-1]) # 将聚类分配的结果重新塑形为与原始特征描述符数组train_des和test_des在除最后一个维度外的形状相匹配。最后一个维度（在这个场景下是128，即每个描述符的长度）被忽略，因为聚类分配的结果是基于每个描述符而不是每个维度进行的\n",
        "test_reAssignments = test_assignments.reshape(test_des.shape[:-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4HDos5XprFo"
      },
      "source": [
        "## 3. Image Representation using BoW\n",
        "Task 3: Represent each image in the training and the test dataset as a histogram of visual words (i.e. represent each image using the Bag of Words representation). Normalise the histograms by their L1 norm. [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq8tI6-LqNzH"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "# Step 1: For each image, create a histogram of the descriptors\n",
        "# i.e. a histogram of the allocated clusters\n",
        "def create_histogram(assignments, K):\n",
        "    histograms = np.zeros((assignments.shape[0], K))\n",
        "    for i in range(assignments.shape[0]):\n",
        "      hist, _ = np.histogram(assignments[i], bins=np.arange(K+1)) # 在np.histogram函数中，bins参数定义了直方图的分组依据，即你希望数据被分割成多少个区间。通过指定bins=np.arange(K+1)，你告诉函数使用一个包含从0到K（包含K）的整数序列作为边界来创建直方图的区间。\n",
        "      histograms[i, :] = hist\n",
        "    return histograms\n",
        "\n",
        "# 每一行代表着训练数据集中的一个样本。\n",
        "#每一列代表着一个聚类中心（或者说是一个聚类）。这里的 K 是聚类的数量，因此就有 K 个列。\n",
        "# 每个单元格的值表示对应样本分配给对应聚类的次数（即直方图中每个聚类的频数）。\n",
        "train_histograms = create_histogram(train_reAssignments, K)\n",
        "test_histograms = create_histogram(test_reAssignments, K) # histograms是一个二维数组，每行代表一张图像的直方图，列数等于聚类的数量K\n",
        "\n",
        "# Step 2: Normalize by the L1 norm of the vector\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "# 直方图通过L1范数进行归一化。L1范数归一化是指将直方图的每个元素除以直方图所有元素的绝对值之和，确保每个直方图向量的元素之和为1。这一步骤通常用于确保模型不会因为图像大小不同而受到影响，同时使特征向量更易于机器学习模型处理\n",
        "train_histograms= normalize(train_histograms, norm='l1', axis=1)\n",
        "test_histograms = normalize(test_histograms, norm='l1', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eoCiLwDWqWwS"
      },
      "source": [
        "## 4. Image Classification using a Nearest Neighbour Classifier\n",
        "Task 4: Implement the Euclidean distance for the multi-dimensional case. Using sklearn [KNN classifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) and the distance implemented  (passed using keyword argument `metric`, check KNN API for details), train a model on the train set BoW, for K=1 [3 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w5Vf5_SrocT"
      },
      "outputs": [],
      "source": [
        "def euclidean_distance(hist_1: np.array, hist_2: np.array):\n",
        "    \"\"\"\n",
        "      hist_1: a 1D vector representing a histogram\n",
        "      hist_2: a 1D vector representing a histogram\n",
        "      returns:\n",
        "      The distance between two histograms (float)\n",
        "    \"\"\"\n",
        "    dist = 0\n",
        "    ### YOUR CODE HERE\n",
        "    squared_diff = np.sum((hist_1 - hist_2) ** 2)\n",
        "    dist = np.sqrt(squared_diff)\n",
        "\n",
        "    return dist\n",
        "\n",
        "### YOUR CODE HERE\n",
        "knn_euclidean = KNeighborsClassifier(n_neighbors=1, metric=euclidean_distance)\n",
        "knn_euclidean.fit(train_histograms, train_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjbkaJW4rqxR"
      },
      "source": [
        "Task 5: Implement a method for histogram intersection [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nALLNqJNrxGH"
      },
      "outputs": [],
      "source": [
        "def hist_intersection(hist_1: np.array, hist_2: np.array):\n",
        "  \"\"\"\n",
        "    hist_1: a 1D vector representing a histogram\n",
        "    hist_2: a 1D vector representing a histogram\n",
        "    returns:\n",
        "    The distance between two histograms (float)\n",
        "  \"\"\"\n",
        "  dist = 0.\n",
        "  ### YOUR CODE HERE\n",
        "  dist = np.sum(np.minimum(hist_1, hist_2))\n",
        "  return dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm47V_IHr3Gw"
      },
      "source": [
        "Task 6: Train a second classifier using the `hist_intersection()` as the distance metric . <font color = 'red'> Evaluate both classifiers on the test set (in terms of accuracy and confusion matrices) and discuss results.</font> [3 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6LMqHAKr2mQ"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "knn_intersection = KNeighborsClassifier(n_neighbors=1, metric=hist_intersection)\n",
        "knn_intersection.fit(train_histograms, train_label)\n",
        "\n",
        "test_pred_euclidean = knn_euclidean.predict(test_histograms)\n",
        "test_pred_intersection = knn_intersection.predict(test_histograms)\n",
        "\n",
        "accuracy_euclidean = accuracy_score(test_label, test_pred_euclidean)\n",
        "accuracy_intersection = accuracy_score(test_label, test_pred_intersection)\n",
        "\n",
        "confusion_euclidean = confusion_matrix(test_label, test_pred_euclidean)\n",
        "confusion_intersection = confusion_matrix(test_label, test_pred_intersection)\n",
        "\n",
        "print(\"Euclidean Distance  Accuracy:\", accuracy_euclidean)\n",
        "print(\"Euclidean Distance Confusion Matrix:\\n\", confusion_euclidean)\n",
        "print(\"Histogram Intersection Accuracy:\", accuracy_intersection)\n",
        "print(\"Histogram Intersection Confusion Matrix:\\n\", confusion_intersection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pjv5l0Ws4lp"
      },
      "source": [
        "## 5. Dictionary size\n",
        "\n",
        "Task 7: <font color = 'red'>  Repeat steps 1-6 using a very small dictionary size (eg. 5). Compute the accuracy and confusion matrices and discuss the drop in performance </font> [2 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rQjQn1wptdGH"
      },
      "outputs": [],
      "source": [
        "### YOUR CODE HERE\n",
        "K_small = 5\n",
        "kmeans_small = KMeans(n_clusters=K_small, random_state=42)\n",
        "kmeans_small.fit(subset_descriptors)\n",
        "dictionary_small = kmeans_small.cluster_centers_\n",
        "\n",
        "train_assignments_small = kmeans_small.predict(train_des.reshape(-1, 128))\n",
        "test_assignments_small = kmeans_small.predict(test_des.reshape(-1, 128))\n",
        "\n",
        "train_reAssignments_small = train_assignments_small.reshape(train_des.shape[:-1])\n",
        "test_reAssignments_small = test_assignments_small.reshape(test_des.shape[:-1])\n",
        "\n",
        "\n",
        "train_histograms_small=create_histogram(train_reAssignments_small, K)\n",
        "test_histograms_small=create_histogram(test_reAssignments_small, K)\n",
        "train_histograms_small= normalize(train_reAssignments_small, norm='l1', axis=1)\n",
        "test_histograms_small = normalize(test_reAssignments_small, norm='l1', axis=1)\n",
        "\n",
        "\n",
        "knn_euclidean_small = KNeighborsClassifier(n_neighbors=1, metric=euclidean_distance)\n",
        "knn_euclidean_small.fit(train_histograms_small, train_label)\n",
        "\n",
        "knn_intersection_small = KNeighborsClassifier(n_neighbors=1, metric=hist_intersection)\n",
        "knn_intersection_small.fit(train_histograms_small, train_label)\n",
        "\n",
        "\n",
        "test_pred_euclidean_small = knn_euclidean_small.predict(test_histograms_small)\n",
        "test_pred_intersection_small = knn_intersection_small.predict(test_histograms_small)\n",
        "\n",
        "accuracy_euclidean_small = accuracy_score(test_label, test_pred_euclidean_small)\n",
        "accuracy_intersection_small = accuracy_score(test_label, test_pred_intersection_small)\n",
        "\n",
        "confusion_euclidean_small = confusion_matrix(test_label, test_pred_euclidean_small)\n",
        "confusion_intersection_small = confusion_matrix(test_label, test_pred_intersection_small)\n",
        "\n",
        "print(\"Small Dictionary Size Euclidean Distance Accuracy:\", accuracy_euclidean_small)\n",
        "print(\"Small Dictionary Size Euclidean Distance Confusion Matrix:\\n\", confusion_euclidean_small)\n",
        "print(\"Small Dictionary Size Histogram Intersection Accuracy:\", accuracy_intersection_small)\n",
        "print(\"Small Dictionary Size Histogram Intersection Confusion Matrix:\\n\", confusion_intersection_small)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MATPN_ectetj"
      },
      "source": [
        "## 6. Support Vector Machines\n",
        "In this section we will train a linear [SVM classifier](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html).\n",
        "\n",
        "\n",
        "Task 8: Using [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) select optimal hyperparameters `C` and `gamma`.\n",
        "\n",
        "<font color = 'red'> Evaluate SVC classifier on the test set (in terms of accuracy and confusion matrices) and compare to the KNN classifier results. </font>\n",
        "\n",
        "<font color = 'red'> For each class show some images that are correctly classified and some images that are incorrectly classified. </font>\n",
        "\n",
        "<font color = 'red'> Can you explain some of the failures?</font> [3 marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yw-Zs5luv2F9"
      },
      "outputs": [],
      "source": [
        "parameters = {'gamma':[2**x for x in np.arange(-1, 1.6, 0.1)], 'C':[2**x for x in range(1, 11)]} # gamma和C是支持向量机（SVC）中的两个重要的超参数。gamma参数定义了单个训练样本的影响范围，值越大表示样本的影响范围越小。C是正则化参数，用于控制误分类的惩罚程度，值越大表示允许的误分类数量越少\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "#Grid Search是一种常用的超参数优化技术，它通过穷举搜索给定超参数的组合，然后评估每个组合的性能，最终选择表现最好的超参数组合。对于每一组超参数的组合，Grid Search使用交叉验证来评估模型的性能，通常采用k折交叉验证，其中数据被划分为k个子集，每次使用其中k-1个子集进行训练，然后在剩余的子集上进行验证。这样可以更准确地估计模型的性能，同时避免了对单一数据划分的依赖性。\n",
        "svc = SVC()\n",
        "grid_search = GridSearchCV(svc, parameters, cv=5, scoring='accuracy') # cv=5 意味着采用了5折交叉验证，即数据集被分成5个子集，其中4个用于训练，1个用于验证\n",
        "grid_search.fit(train_histograms, train_label)\n",
        "\n",
        "best_svc = grid_search.best_estimator_ # 一个已经在训练数据上训练好的支持向量机模型，它使用了在网格搜索过程中确定的最佳超参数组合\n",
        "test_pred_svc = best_svc.predict(test_histograms)\n",
        "\n",
        "\n",
        "accuracy_svc = accuracy_score(test_label, test_pred_svc)\n",
        "confusion_svc = confusion_matrix(test_label, test_pred_svc)\n",
        "\n",
        "print(\"SVC Classifier Accuracy:\", accuracy_svc)\n",
        "print(\"SVC Classifier Confusion Matrix:\\n\", confusion_svc)\n",
        "\n",
        "\n",
        "correct_indices = np.where(test_pred_svc == test_label)[0] #np.where(test_pred_svc == test_label) 函数会返回满足条件的元素的索引，即预测正确的样本在 test_pred_svc 数组中的索引。\n",
        "#[0] 表示取出返回的元组中的第一个元素，这是因为 np.where() 返回的是一个元组，其中包含了符合条件的元素索引，而在这个特定的情况下，我们只关心索引值。\n",
        "incorrect_indices = np.where(test_pred_svc != test_label)[0]\n",
        "\n",
        "\n",
        "example_img = list()\n",
        "for root, dirs, _ in os.walk('image/'):\n",
        "    for class_folder in dirs:\n",
        "      img_files = os.listdir(os.path.join(root, class_folder))\n",
        "      img_files = [\n",
        "          os.path.join(*[root, class_folder, filename]) for filename in img_files\n",
        "          ]\n",
        "      example_img.extend(img_files[-20:])\n",
        "\n",
        "test_images = list()\n",
        "for imgf in example_img:\n",
        "    img = cv2.imread(imgf)\n",
        "    if img is not None:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        test_images.append(img)\n",
        "    else:\n",
        "        print(f\"Failed to load image: {imgf}\")  # Print the path of any image that fails to load\n",
        "\n",
        "\n",
        "class_labels_arrary = [0, 1, 2, 3, 4]\n",
        "\n",
        "def show_images_by_class(indices, class_label, img_lst, class_labels, title):\n",
        "    print(f'{title} for class {class_label}:')\n",
        "    class_indices = [i for i in indices if class_labels[i] == class_label]\n",
        "    if len(class_indices) > 0:\n",
        "        num_images_to_show = min(len(class_indices), 5)  # Show up to 5 images\n",
        "        fig, axs = plt.subplots(1, num_images_to_show, figsize=(15, 3))\n",
        "        if num_images_to_show == 1:\n",
        "            axs = [axs]  # Make it iterable\n",
        "        for idx, ax in enumerate(axs):\n",
        "            if idx < len(class_indices):  # Check if index is within range\n",
        "                img_index = class_indices[idx]\n",
        "                if img_index < len(img_lst):  # Ensure img_index is valid for img_lst\n",
        "                    ax.imshow(img_lst[img_index])\n",
        "                    # Updated title to include predicted and ground truth labels\n",
        "                    ax.set_title(f\"Ground Truth: {class_label} \\n Predicted: {test_pred_svc[img_index]}\")\n",
        "                    ax.axis('off')\n",
        "                else:\n",
        "                    print(f\"Index {img_index} out of range for img_lst.\")\n",
        "            else:\n",
        "                print(f\"No more images to show for class {class_label}.\")\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(f\"No images found for class {class_label}.\")\n",
        "\n",
        "for class_label in class_labels_arrary:\n",
        "    show_images_by_class(correct_indices, class_label, test_images, test_label, \"Correctly Classified Images\")\n",
        "    show_images_by_class(incorrect_indices, class_label, test_images, test_label, \"Incorrectly Classified Images\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7PBOE8Axfv6"
      },
      "source": [
        "## 7. Handing in\n",
        "\n",
        "Create a folder that will contain:\n",
        "\n",
        "• A .pdf report that contains the answers to the exercises\n",
        "• The programs files\n",
        "\n",
        "Create a .zip file and submit electronically on QMplus.\n",
        "\n",
        "IMPORTANT: Plagiarism (copying from other students, or copying the work of others without proper referencing) is cheating, and will not be tolerated.\n",
        "\n",
        "IF TWO “FOLDERS” ARE FOUND TO CONTAIN IDENTICAL MATERIAL, BOTH WILL BE GIVEN A MARK OF ZERO.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
