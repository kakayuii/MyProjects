{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054122be-e618-4594-a24c-f8e1b7717c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ef374b-41d1-4fa9-9008-18b386d0e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object Counting\n",
    "# question a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda7f168-728c-40dd-890a-e76f6ef58e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "vid_obj = cv2.VideoCapture('DatasetC.mpg')\n",
    "\n",
    "# Read frames\n",
    "ret, reference_frame = vid_obj.read()\n",
    "ret, frame1 = vid_obj.read()\n",
    "for _ in range(98):  # Skipping 98 frames to get to the 100th frame\n",
    "    ret, _ = vid_obj.read()\n",
    "ret, frame2 = vid_obj.read()\n",
    "\n",
    "# Convert frames to RGB (assuming they are in BGR format)\n",
    "reference_frame = cv2.cvtColor(reference_frame, cv2.COLOR_BGR2RGB)\n",
    "frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2RGB) #frame1\n",
    "frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2RGB) #frame100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1676d723-ec47-4c9e-b7c7-4dad1333cf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_rgb2grayscale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf433afc-098e-4ebe-b427-d3421159b3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ICV_TemporalDifference(reference_frame, frame, threshold):\n",
    "    if reference_frame.shape != frame.shape:\n",
    "        raise ValueError(\"Input images must have the same shape.\")\n",
    "        \n",
    "    frame_difference = np.abs(reference_frame.astype(np.int32) - frame.astype(np.int32))\n",
    "    threshold_result = (frame_difference > threshold).astype(np.uint8) * 255\n",
    "    return frame_difference, threshold_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff604634-e3d6-498a-8f9d-015af9a51fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(1)\n",
    "plt.imshow(reference_frame)\n",
    "plt.axis('off')\n",
    "plt.savefig('referenceFrame.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4de4-f79d-44b3-a492-2de4da90b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(2)\n",
    "plt.imshow(frame1)\n",
    "plt.axis('off')\n",
    "plt.savefig('frame1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0834c1e-694e-4892-aae3-b38fbb7728b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(3)\n",
    "plt.imshow(frame2)\n",
    "plt.axis('off')\n",
    "plt.savefig('frame100.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a491be-d100-4e11-b858-0d78aec46f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Threshold = 20\n",
    "\n",
    "ReferenceFrame=ICV_rgb2grayscale(reference_frame)\n",
    "GrayFrame1=ICV_rgb2grayscale(frame1)\n",
    "GrayFrame2=ICV_rgb2grayscale(frame2)\n",
    "\n",
    "frame_difference1, threshold_result1 = ICV_TemporalDifference(ReferenceFrame, GrayFrame1, Threshold)\n",
    "frame_difference2, threshold_result2 = ICV_TemporalDifference(ReferenceFrame, GrayFrame2, Threshold)\n",
    "plt.figure(4)\n",
    "plt.imshow(frame_difference1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig('FrameDifferencing1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb19de2f-b991-4203-ab62-39cf852bc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(5)\n",
    "plt.imshow(threshold_result1, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig('ThresholdResult1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ed7547-c1de-4638-81ae-f0cf56e8949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(6)\n",
    "plt.imshow(frame_difference2, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig('FrameDifferencing2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2cb06-ab33-4e55-8a75-5b6e6c363ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(7)\n",
    "plt.imshow(threshold_result2, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.savefig('ThresholdResult2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5925747f-24b4-4eb7-8dde-2a3d712ff623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0b43a8-d156-4ba9-b366-7ead3987ee25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the video file\n",
    "def ICV_sequenceFrameDiff():\n",
    "    vid_obj_b = cv2.VideoCapture('DatasetC.mpg')\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, reference_frame_b = vid_obj_b.read()\n",
    "    \n",
    "    reference_frame_b = cv2.cvtColor(reference_frame_b, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Loop through the frames\n",
    "    for iFrame in range(2, int(vid_obj_b.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "        print(f'Frame #{iFrame} | Reference Frame #{iFrame-1}')\n",
    "    \n",
    "        # Read current frame\n",
    "        ret, current_frame = vid_obj_b.read()\n",
    "    \n",
    "        # Check if the frame is read successfully\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {iFrame}.\")\n",
    "            break\n",
    "    \n",
    "        current_frame = cv2.cvtColor(current_frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    \n",
    "        gray_frame1=ICV_rgb2grayscale(reference_frame_b)\n",
    "        gray_frame2=ICV_rgb2grayscale(current_frame)\n",
    "    \n",
    "    \n",
    "        # Display the current frame\n",
    "        plt.figure(8)\n",
    "        plt.imshow(current_frame)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Reference Frame #{iFrame-1} |Frame #{iFrame}')\n",
    "    \n",
    "        # # Calculate frame differencing and threshold\n",
    "        threshold_value = 20\n",
    "        frame_differencing, threshold_result = ICV_TemporalDifference(gray_frame1, gray_frame2, threshold_value)\n",
    "    \n",
    "        # # Display frame differencing\n",
    "        plt.figure(9)\n",
    "        plt.imshow(frame_differencing, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Reference Frame #{iFrame-1} |Frame #{iFrame}')\n",
    "    \n",
    "        # # Display threshold result\n",
    "        plt.figure(10)\n",
    "        plt.imshow(threshold_result, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Reference Frame #{iFrame-1} |Frame #{iFrame}')\n",
    "    \n",
    "        reference_frame_b = current_frame\n",
    "        \n",
    "        # # Show the figures\n",
    "        plt.show()\n",
    "    # Release the video capture object\n",
    "    vid_obj_b.release()\n",
    "\n",
    "ICV_sequenceFrameDiff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9c9fe8-8789-4b60-bb81-477a21524be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959868c8-845c-4683-9658-fcf7bfb0bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_obj_c = cv2.VideoCapture('DatasetC.mpg')\n",
    "\n",
    "def ICV_generateBackground(vid_object):\n",
    "    # Open the video file\n",
    "    \n",
    "    threshold = 20\n",
    "    \n",
    "    # Read the first frame\n",
    "    ret, reference_frame_c = vid_object.read()\n",
    "    \n",
    "    reference_frame_c = cv2.cvtColor(reference_frame_c, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Get image dimensions\n",
    "    H, W, _ = reference_frame_c.shape\n",
    "    \n",
    "    num_pixel = np.zeros((H, W), dtype=int)\n",
    "    background = np.zeros((H, W, 3), dtype=float)\n",
    "    image = np.zeros((H, W, 3), dtype=float)\n",
    "    \n",
    "    # Loop through the frames\n",
    "    for iFrame in range(2, int(vid_object.get(cv2.CAP_PROP_FRAME_COUNT))):\n",
    "    \n",
    "        # Read frames\n",
    "        ret, currentFrame = vid_object.read()\n",
    "    \n",
    "        # Check if the frame is read successfully\n",
    "        if not ret:\n",
    "            print(f\"Error: Could not read frame {iFrame}.\")\n",
    "            break\n",
    "    \n",
    "        grayFrame1 = ICV_rgb2grayscale(reference_frame_c)\n",
    "        grayFrame2 = ICV_rgb2grayscale(currentFrame)\n",
    "    \n",
    "        # Calculate frame differencing and threshold\n",
    "        _, threshold_result = ICV_TemporalDifference(grayFrame1, grayFrame2, threshold)\n",
    "    \n",
    "        # Update pixel count and accumulate pixel values\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                if threshold_result[i, j] == 0:\n",
    "                    num_pixel[i, j] += 1\n",
    "                    image[i, j, :] += currentFrame[i, j, :]\n",
    "                    \n",
    "        reference_frame_c=currentFrame\n",
    "    \n",
    "    \n",
    "    # Calculate the background\n",
    "    for i in range(H):\n",
    "        for j in range(W):\n",
    "            if num_pixel[i, j] != 0:\n",
    "                background[i, j, :] = image[i, j, :] / num_pixel[i, j]\n",
    "    \n",
    "    background = np.uint8(background)\n",
    "    \n",
    "    # Display the background\n",
    "    plt.imshow(cv2.cvtColor(background, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    # Release the video capture object\n",
    "    vid_object.release()\n",
    "    \n",
    "    return background\n",
    "\n",
    "background = ICV_generateBackground(vid_obj_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9617b30f-c7e1-4f24-aaef-e03e0a61ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5f69d-2b15-4fd5-a8b3-1ead08829cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_contours(binary_diff):\n",
    "    contours = []\n",
    "    height, width = binary_diff.shape[:2]\n",
    "    visited = np.zeros_like(binary_diff)\n",
    "\n",
    "    def dfs(x, y, current_contour):\n",
    "        stack = [(x, y)]\n",
    "        while stack:\n",
    "            cx, cy = stack.pop()\n",
    "            if (\n",
    "                cx < 0\n",
    "                or cy < 0\n",
    "                or cx >= height\n",
    "                or cy >= width\n",
    "                or binary_diff[cx, cy] == 0\n",
    "                or visited[cx, cy] == 1\n",
    "            ):\n",
    "                continue\n",
    "            visited[cx, cy] = 1\n",
    "            current_contour.append((cx, cy))\n",
    "            for dx in range(-1, 2):\n",
    "                for dy in range(-1, 2):\n",
    "                    stack.append((cx + dx, cy + dy))\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if binary_diff[i, j] == 255 and visited[i, j] == 0:\n",
    "                current_contour = []\n",
    "                dfs(i, j, current_contour)\n",
    "                if current_contour:\n",
    "                    # Calculate the center of the contours\n",
    "                    contours_center = (\n",
    "                        sum([x for x, y in current_contour]) // len(current_contour),\n",
    "                        sum([y for x, y in current_contour]) // len(current_contour),\n",
    "                    )\n",
    "                    current_contour.append(contours_center)\n",
    "                    contours.append(current_contour)\n",
    "\n",
    "    return contours\n",
    "\n",
    "def ICV_countObjects(binary_diff, min_contour_area=100):\n",
    "    contours = find_contours(binary_diff)\n",
    "    # Count contours with area greater than a threshold (min_contour_area)\n",
    "    num_objects = sum(cv2.contourArea(np.array(contour)) > min_contour_area for contour in contours if len(contour) > 2)\n",
    "\n",
    "    return num_objects\n",
    "\n",
    "\n",
    "def ICV_countObjectVideo(videoFrames, threshold):\n",
    "    videoFrames = np.array(videoFrames)\n",
    "    numberOfObjects = []\n",
    "    \n",
    "    # Use the first frame as the background\n",
    "    background = ICV_rgb2grayscale(videoFrames[0])\n",
    "    \n",
    "    # Count the number based on different frames\n",
    "    for i in range(1, len(videoFrames)):\n",
    "        _, threshold_result = ICV_TemporalDifference(background, ICV_rgb2grayscale(videoFrames[i]), threshold)\n",
    "        num_objects = ICV_countObjects(threshold_result)\n",
    "        numberOfObjects.append(num_objects)\n",
    "\n",
    "    return numberOfObjects\n",
    "\n",
    "# Open the video file\n",
    "vid_object = cv2.VideoCapture('DatasetC.mpg')\n",
    "\n",
    "# Check if the video file is opened successfully\n",
    "if not vid_object.isOpened():\n",
    "    print(\"Error: Could not open the video file.\")\n",
    "    exit()\n",
    "\n",
    "# Read the video frames\n",
    "vid_frames = []\n",
    "while True:\n",
    "    ret, frame = vid_object.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    vid_frames.append(frame)\n",
    "\n",
    "# Close the video file\n",
    "vid_object.release()\n",
    "\n",
    "# Count the number of objects in each frame\n",
    "num_objects_list = ICV_countObjectVideo(vid_frames, 20)\n",
    "\n",
    "# Plot the results\n",
    "frame_numbers = np.arange(2, len(num_objects_list) + 2)  # Adjusted frame numbers (starting from the 2nd frame)\n",
    "plt.bar(frame_numbers, num_objects_list)\n",
    "plt.xlabel('Frame Number')\n",
    "plt.ylabel('Number of Objects')\n",
    "plt.title('Number of Moving Objects in Each Frame')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
